# ============================================================================
# Embeddings Service - Environment Configuration Example
# ============================================================================
# Copy this file to .env and update the values according to your setup
# Command: cp .env_example .env

# ============================================================================
# Model Configuration - Dual Model Architecture
# ============================================================================

# Fast Model: For quick responses (chat, support bots, short messages)
# Recommended: 768 dimensions, fast inference
MODEL_FAST=intfloat/multilingual-e5-base

# Thinking Model: For deep analysis (long documents, emails, articles)
# Recommended: 1024 dimensions, better semantic understanding
MODEL_THINKING=intfloat/multilingual-e5-large

# Alternative model options:
# - BAAI/bge-base-en-v1.5 (English only, 768 dim)
# - sentence-transformers/all-MiniLM-L6-v2 (English, 384 dim, fastest)
# - BAAI/bge-m3 (Multilingual, 1024 dim, requires PyTorch 2.6+)

# Device for model inference
# Options: auto, cpu, cuda, mps (Metal Performance Shaders for Apple Silicon)
# "auto" will automatically select the best available device
DEVICE=auto

# Batch size for processing multiple texts simultaneously
# Higher values = faster processing but more memory usage
# Recommended: 16-64 for GPU, 8-32 for CPU
BATCH_SIZE=32

# ============================================================================
# Server Configuration
# ============================================================================

# Port for REST API (FastAPI)
# Default: 8000
REST_PORT=8000

# Port for gRPC API
# Default: 50051
GRPC_PORT=50051

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level for the application
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# Authentication Configuration
# ============================================================================

# Admin Password for web dashboard login
# Default: admin123 (CHANGE THIS IN PRODUCTION!)
# Used for accessing /admin/login interface
# 
# ⚠️  SECURITY WARNING:
# - Change this immediately for production deployments
# - Use a strong password (min 12 characters, mix of upper/lower/numbers/symbols)
# - Never commit the actual password to version control
# - Consider implementing password hashing in production
#
# Example: ADMIN_PASSWORD=MyS3cur3P@ssw0rd!2025
ADMIN_PASSWORD=admin123

# API Keys for authentication (comma-separated)
# Format: account_name:api_key,account_name2:api_key2
# 
# ⚠️  SECURITY NOTE: 
# - Use strong, unique API keys in production
# - Consider using a secrets management system for production deployments
# - API keys should be at least 32 characters long
# - Use the format: sk-{account}-{random-string} for consistency
#
# Example API key generation (Linux/macOS):
# openssl rand -base64 32
# 
# Example accounts (replace with your own secure keys):
API_KEYS=admin:sk-admin-REPLACE-WITH-SECURE-KEY,user1:sk-user1-REPLACE-WITH-SECURE-KEY,app1:sk-app1-REPLACE-WITH-SECURE-KEY,monitoring:sk-monitor-REPLACE-WITH-SECURE-KEY

# ============================================================================
# Production Considerations
# ============================================================================

# For production deployments, consider:
# 
# 1. Security:
#    - Use environment-specific .env files (.env.production, .env.staging)
#    - Store sensitive values in secure secret management systems
#    - Rotate API keys regularly
#    - Use HTTPS/TLS for all communications
# 
# 2. Performance:
#    - Adjust BATCH_SIZE based on available memory
#    - Use GPU (DEVICE=cuda) for better performance if available
#    - Consider model size vs performance trade-offs
# 
# 3. Monitoring:
#    - Set LOG_LEVEL=INFO or WARNING in production
#    - Configure proper log aggregation and monitoring
#    - Create dedicated monitoring API keys with limited permissions
# 
# 4. Scalability:
#    - Use load balancers for multiple service instances
#    - Consider horizontal scaling with multiple replicas
#    - Monitor resource usage and scale accordingly

# ============================================================================
# Vector Database Configuration
# ============================================================================

# Storage path for vector database files
# Default: ./vdb-data (development) or /srv/vdb-data (production)
# This directory will store all projects, collections, and vector data
VDB_STORAGE_PATH=./vdb-data

# ============================================================================
# Development vs Production Examples
# ============================================================================

# Development Configuration:
# MODEL_ID=sentence-transformers/all-MiniLM-L6-v2  # Smaller, faster model
# DEVICE=cpu                                        # CPU for development
# BATCH_SIZE=16                                     # Smaller batch size
# LOG_LEVEL=DEBUG                                   # Verbose logging
# API_KEYS=dev:sk-dev-key,test:sk-test-key        # Simple keys for testing
# VDB_STORAGE_PATH=./vdb-data                      # Local storage

# Production Configuration:
# MODEL_ID=BAAI/bge-base-en-v1.5                  # Production-quality model
# DEVICE=cuda                                       # GPU acceleration
# BATCH_SIZE=64                                     # Optimized batch size
# LOG_LEVEL=INFO                                    # Production logging
# API_KEYS=prod-api:sk-prod-very-long-secure-key,monitoring:sk-monitor-secure-key
# VDB_STORAGE_PATH=/srv/vdb-data                   # Production storage path