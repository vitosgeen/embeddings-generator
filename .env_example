# ============================================================================
# Embeddings Service - Environment Configuration Example
# ============================================================================
# Copy this file to .env and update the values according to your setup
# Command: cp .env_example .env

# ============================================================================
# Model Configuration
# ============================================================================

# Sentence Transformer model ID from Hugging Face
# Popular options:
# - BAAI/bge-base-en-v1.5 (English, 768 dim, good general purpose)
# - sentence-transformers/all-MiniLM-L6-v2 (English, 384 dim, fast)
# - sentence-transformers/all-mpnet-base-v2 (English, 768 dim, high quality)
# - intfloat/multilingual-e5-base (Multilingual, 768 dim)
MODEL_ID=BAAI/bge-base-en-v1.5

# Device for model inference
# Options: auto, cpu, cuda, mps (Metal Performance Shaders for Apple Silicon)
# "auto" will automatically select the best available device
DEVICE=auto

# Batch size for processing multiple texts simultaneously
# Higher values = faster processing but more memory usage
# Recommended: 16-64 for GPU, 8-32 for CPU
BATCH_SIZE=32

# ============================================================================
# Server Configuration
# ============================================================================

# Port for REST API (FastAPI)
# Default: 8000
REST_PORT=8000

# Port for gRPC API
# Default: 50051
GRPC_PORT=50051

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level for the application
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# Authentication Configuration
# ============================================================================

# API Keys for authentication (comma-separated)
# Format: account_name:api_key,account_name2:api_key2
# 
# ⚠️  SECURITY NOTE: 
# - Use strong, unique API keys in production
# - Consider using a secrets management system for production deployments
# - API keys should be at least 32 characters long
# - Use the format: sk-{account}-{random-string} for consistency
#
# Example API key generation (Linux/macOS):
# openssl rand -base64 32
# 
# Example accounts (replace with your own secure keys):
API_KEYS=admin:sk-admin-REPLACE-WITH-SECURE-KEY,user1:sk-user1-REPLACE-WITH-SECURE-KEY,app1:sk-app1-REPLACE-WITH-SECURE-KEY,monitoring:sk-monitor-REPLACE-WITH-SECURE-KEY

# ============================================================================
# Production Considerations
# ============================================================================

# For production deployments, consider:
# 
# 1. Security:
#    - Use environment-specific .env files (.env.production, .env.staging)
#    - Store sensitive values in secure secret management systems
#    - Rotate API keys regularly
#    - Use HTTPS/TLS for all communications
# 
# 2. Performance:
#    - Adjust BATCH_SIZE based on available memory
#    - Use GPU (DEVICE=cuda) for better performance if available
#    - Consider model size vs performance trade-offs
# 
# 3. Monitoring:
#    - Set LOG_LEVEL=INFO or WARNING in production
#    - Configure proper log aggregation and monitoring
#    - Create dedicated monitoring API keys with limited permissions
# 
# 4. Scalability:
#    - Use load balancers for multiple service instances
#    - Consider horizontal scaling with multiple replicas
#    - Monitor resource usage and scale accordingly

# ============================================================================
# Development vs Production Examples
# ============================================================================

# Development Configuration:
# MODEL_ID=sentence-transformers/all-MiniLM-L6-v2  # Smaller, faster model
# DEVICE=cpu                                        # CPU for development
# BATCH_SIZE=16                                     # Smaller batch size
# LOG_LEVEL=DEBUG                                   # Verbose logging
# API_KEYS=dev:sk-dev-key,test:sk-test-key        # Simple keys for testing

# Production Configuration:
# MODEL_ID=BAAI/bge-base-en-v1.5                  # Production-quality model
# DEVICE=cuda                                       # GPU acceleration
# BATCH_SIZE=64                                     # Optimized batch size
# LOG_LEVEL=INFO                                    # Production logging
# API_KEYS=prod-api:sk-prod-very-long-secure-key,monitoring:sk-monitor-secure-key