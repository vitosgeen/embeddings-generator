# Vector Database Service (VDB Service) — Technical Specification
Version: 1.0  
Language: English  
Author: ChatGPT (Generated for Vitaliy)

---

# 1. Overview

The Vector Database Service (VDB Service) is a standalone microservice responsible for storing, searching, and managing vector embeddings generated by the `vector-service`.  
The service is designed for multi-project use, provides automatic sharding, supports multiple collections per project, and offers a clean, stable REST API.

The service hides all internal storage details (sharding, indexing, backend engine) from clients.

---

# 2. Goals

- Provide fast, scalable vector storage and similarity search.
- Support multiple independent projects (multi-tenant mode).
- Support collections within each project (messages, users, automoderation, etc.).
- Automatically shard data for scaling (horizontal partitioning).
- Maintain backward-compatible public API (no exposure of internal sharding).
- Provide optional debug metadata when requested.

---

# 3. Key Concepts

## 3.1 Project
A logical tenant (e.g., a website, product, subsystem).

Each project has isolated:
- storage directory
- shards
- collections

## 3.2 Collection
A table-like structure for embeddings of a specific type.

Examples:
- `support`
- `automoderation`
- `messages`
- `users`

Each collection has:
- fixed vector dimension (e.g., 384)
- metric (cosine / dot / L2)
- shard count
- metadata schema (optional)

## 3.3 Shards
A project-level horizontal partitioning mechanism.

Example structure:
```
project_123/
    collections/
        automoderation/
            shard_0/
            shard_1/
            shard_2/
            shard_3/
```

Shards are transparent to API users.

---

# 4. Storage Architecture

```
/srv/vdb-data/
    project_id/
        _project.json
        collections/
            {collection_name}/
                _config.json
                shard_0/
                shard_1/
                ...
```

Example `_config.json`:

```json
{
  "name": "automoderation",
  "dimension": 384,
  "metric": "cosine",
  "shards": 4,
  "created_at": 1735000000
}
```

---

# 5. REST API Specification

## 5.1 Create Project (optional)
```
POST /projects
```
Creates a new project directory and metadata file.

---

## 5.2 List Collections
```
GET /projects/{project_id}/collections
```

---

## 5.3 Create Collection
```
POST /projects/{project_id}/collections
```

### Request
```json
{
  "name": "automoderation",
  "dimension": 384,
  "metric": "cosine",
  "shards": 4,
  "description": "Embeddings for automated moderation"
}
```

### Response
```json
{
  "status": "ok",
  "collection": "automoderation",
  "dimension": 384,
  "metric": "cosine",
  "shards": 4
}
```

---

## 5.4 Add Vector
```
POST /projects/{project_id}/collections/{collection}/add
```

### Request
```json
{
  "id": "msg_12345",
  "embedding": [...],
  "metadata": { "lang": "en", "type": "message" },
  "document": "optional raw text"
}
```

### Response
```json
{
  "status": "ok",
  "id": "msg_12345"
}
```

(Optionally, on `?include_debug=true`:)

```json
{
  "status": "ok",
  "id": "msg_12345",
  "debug": {
    "shard": 2,
    "total_records_in_shard": 12234
  }
}
```

---

## 5.5 Search
```
POST /projects/{project_id}/collections/{collection}/search
```

### Request
```json
{
  "query_vector": [...],
  "limit": 10
}
```

### Response
```json
{
  "data": [
    { "id": "msg_1", "score": 0.89, "metadata": {...} },
    { "id": "msg_2", "score": 0.88, "metadata": {...} }
  ]
}
```

If `include_debug=true`:

```json
{
  "data": [...],
  "debug": {
    "total_records": 128223,
    "shard_results": [
      { "shard": 0, "count": 32300, "search_time_ms": 12 },
      { "shard": 1, "count": 28000, "search_time_ms": 14 },
      { "shard": 2, "count": 34000, "search_time_ms": 11 },
      { "shard": 3, "count": 34000, "search_time_ms": 13 }
    ]
  }
}
```

---

## 5.6 Delete Vector
```
DELETE /projects/{project_id}/collections/{collection}/vectors/{id}
```

---

# 6. Sharding Specification

### shard_id = hash(id) % shard_count

The system performs:
- single-shard writes  
- multi-shard parallel reads  
- aggregation of top-K results  

Sharding is **fully internal** and never exposed unless debug mode is explicitly requested.

---

# 7. Vector Schema (internal)

```
id: string
vector: float[]
metadata: dict
document: string | None
created_at: int
updated_at: int
shard_id: int
deleted: bool (soft delete)
```

---

# 8. Performance Requirements

### Inserts
- Batch insert (100 vectors) ≤ 100 ms

### Search
- 4 shards → ≤ 30 ms
- 8 shards → ≤ 15–20 ms

### Scaling
- Up to 1–5 million vectors per collection (LanceDB/Chroma)
- Future upgrade path: Qdrant backend

---

# 9. Security

- `X-API-Key` required on all endpoints
- Rate limiting per project
- Requests must not reveal storage engine or shard topology

---

# 10. Non-Functional Requirements

- Local persistent storage (no external DB required)
- Clean Architecture structure:
  - domain/
  - usecases/
  - adapters/
  - infra/
- PM2 or Supervisor-compatible run mode
- Debug info optional via `include_debug=true`

---

# 11. Future Extensions

- Project export/import (ZIP)
- Re-sharding (increase shard count)
- Index compression
- Metadata indexing for filtering
- gRPC interface

---

# 12. Summary

This technical specification defines a scalable, isolated, shard-based vector database service suitable for multiple internal company projects.  
The API is stable and does not expose internal mechanics, ensuring easy adoption across all systems.

